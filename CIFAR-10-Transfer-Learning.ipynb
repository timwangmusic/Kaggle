{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import cifar10\n",
    "from keras import models\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg19 import VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding\n",
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image enlargement\n",
    "import scipy.misc\n",
    "big_x_train = np.array([scipy.misc.imresize(x_train[i], (64, 64, 3)) \n",
    "                            for i in range(len(x_train))]).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_rows, img_cols, channels = big_x_train.shape[1], big_x_train.shape[2], big_x_train.shape[3]\n",
    "img_rows, img_cols, channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model = VGG19(include_top = False, input_shape = (img_rows, img_cols, channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate features from VGG16 model\n",
    "X_train_vgg_features = vgg_model.predict(big_x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_images_features(imgs, target_size, model):\n",
    "    \"\"\"Increase image size to target size and \n",
    "    extract image features from model\"\"\"\n",
    "    large_imgs = np.array([scipy.misc.imresize(img, target_size) for img in imgs])\n",
    "    features = model.predict(large_imgs)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_vgg_features = extract_images_features(x_test, (64,64,3), vgg_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2, 2, 512)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_vgg_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer learning\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(filters=128, kernel_size=2, input_shape=X_train_vgg_features.shape[1:]))\n",
    "model.add(layers.Dropout(0.4))\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "40000/40000 [==============================] - 1s - loss: 7.0153 - acc: 0.5190 - val_loss: 5.3445 - val_acc: 0.6310\n",
      "Epoch 2/20\n",
      "40000/40000 [==============================] - 1s - loss: 5.7071 - acc: 0.6149 - val_loss: 5.1797 - val_acc: 0.6498\n",
      "Epoch 3/20\n",
      "40000/40000 [==============================] - 1s - loss: 5.4236 - acc: 0.6372 - val_loss: 5.0538 - val_acc: 0.6619\n",
      "Epoch 4/20\n",
      "40000/40000 [==============================] - 1s - loss: 5.3001 - acc: 0.6473 - val_loss: 4.9673 - val_acc: 0.6691\n",
      "Epoch 5/20\n",
      "40000/40000 [==============================] - 1s - loss: 5.1623 - acc: 0.6580 - val_loss: 4.9577 - val_acc: 0.6705\n",
      "Epoch 6/20\n",
      "40000/40000 [==============================] - 1s - loss: 5.0340 - acc: 0.6668 - val_loss: 4.8456 - val_acc: 0.6787\n",
      "Epoch 7/20\n",
      "40000/40000 [==============================] - 1s - loss: 5.0205 - acc: 0.6692 - val_loss: 4.8441 - val_acc: 0.6810\n",
      "Epoch 8/20\n",
      "40000/40000 [==============================] - 1s - loss: 4.9561 - acc: 0.6735 - val_loss: 4.7950 - val_acc: 0.6817\n",
      "Epoch 9/20\n",
      "40000/40000 [==============================] - 1s - loss: 4.8511 - acc: 0.6814 - val_loss: 4.7400 - val_acc: 0.6877\n",
      "Epoch 10/20\n",
      "40000/40000 [==============================] - 1s - loss: 4.8284 - acc: 0.6834 - val_loss: 4.7796 - val_acc: 0.6861\n",
      "Epoch 11/20\n",
      "40000/40000 [==============================] - 1s - loss: 4.8657 - acc: 0.6816 - val_loss: 4.9320 - val_acc: 0.6789\n",
      "Epoch 12/20\n",
      "40000/40000 [==============================] - 1s - loss: 4.8310 - acc: 0.6842 - val_loss: 4.8487 - val_acc: 0.6830\n",
      "Epoch 13/20\n",
      "40000/40000 [==============================] - 1s - loss: 4.7783 - acc: 0.6879 - val_loss: 4.7298 - val_acc: 0.6913\n",
      "Epoch 14/20\n",
      "40000/40000 [==============================] - 1s - loss: 4.7098 - acc: 0.6920 - val_loss: 4.7015 - val_acc: 0.6926\n",
      "Epoch 15/20\n",
      "40000/40000 [==============================] - 1s - loss: 4.7055 - acc: 0.6935 - val_loss: 4.7445 - val_acc: 0.6895\n",
      "Epoch 16/20\n",
      "40000/40000 [==============================] - 1s - loss: 4.7192 - acc: 0.6934 - val_loss: 4.6714 - val_acc: 0.6937\n",
      "Epoch 17/20\n",
      "40000/40000 [==============================] - 1s - loss: 4.7116 - acc: 0.6932 - val_loss: 4.6912 - val_acc: 0.6942\n",
      "Epoch 18/20\n",
      "40000/40000 [==============================] - 1s - loss: 4.6852 - acc: 0.6958 - val_loss: 4.7707 - val_acc: 0.6910\n",
      "Epoch 19/20\n",
      "40000/40000 [==============================] - 1s - loss: 4.6982 - acc: 0.6953 - val_loss: 4.8866 - val_acc: 0.6834\n",
      "Epoch 20/20\n",
      "40000/40000 [==============================] - 1s - loss: 4.6427 - acc: 0.6986 - val_loss: 4.7017 - val_acc: 0.6953\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbe546cf860>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "               loss = 'categorical_crossentropy',\n",
    "               metrics=['accuracy'])\n",
    "# Training\n",
    "model.fit(X_train_vgg_features, y_train, epochs=20, batch_size=128, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9280/10000 [==========================>...] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.69740000000000002"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test_vgg_features, y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inception model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols, channels = 139, 139, 3\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "inception_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(img_rows, img_cols, channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_x_train = np.array([scipy.misc.imresize(img, (139, 139, 3)) \n",
    "                            for img in x_train]).astype('float32')\n",
    "inception_input_train = preprocess_input(big_x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 139, 139, 3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inception_input_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_inception_features = inception_model.predict(inception_input_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database or disk is full',)).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "# np.savez('inception_features_train', features=X_train_inception_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_inception_features = extract_images_features(x_train, (img_rows, img_cols, channels), inception_model)\n",
    "# X_test_inception_features = extract_images_features(x_test, (img_rows, img_cols, channels), inception_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model building, loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_287 (Conv2D)          (None, 2, 2, 128)         1048704   \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_5 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,049,994.0\n",
      "Trainable params: 1,049,994.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Transfer learning\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(filters=128, kernel_size=2, input_shape=X_train_inception_features.shape[1:]))\n",
    "model.add(layers.Dropout(0.4))\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "               loss = 'categorical_crossentropy',\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "7s - loss: 4.3467 - acc: 0.6744 - val_loss: 3.1810 - val_acc: 0.7626\n",
      "Epoch 2/20\n",
      "6s - loss: 3.0708 - acc: 0.7732 - val_loss: 2.8976 - val_acc: 0.7870\n",
      "Epoch 3/20\n",
      "6s - loss: 2.8895 - acc: 0.7904 - val_loss: 2.9985 - val_acc: 0.7885\n",
      "Epoch 4/20\n",
      "6s - loss: 2.7626 - acc: 0.8015 - val_loss: 3.1425 - val_acc: 0.7744\n",
      "Epoch 5/20\n",
      "6s - loss: 2.6526 - acc: 0.8100 - val_loss: 2.6943 - val_acc: 0.8081\n",
      "Epoch 6/20\n",
      "6s - loss: 2.5876 - acc: 0.8146 - val_loss: 2.6771 - val_acc: 0.8077\n",
      "Epoch 7/20\n",
      "6s - loss: 2.4849 - acc: 0.8230 - val_loss: 2.6520 - val_acc: 0.8122\n",
      "Epoch 8/20\n",
      "6s - loss: 2.4587 - acc: 0.8259 - val_loss: 2.5727 - val_acc: 0.8181\n",
      "Epoch 9/20\n",
      "6s - loss: 2.4573 - acc: 0.8269 - val_loss: 2.9241 - val_acc: 0.7988\n",
      "Epoch 10/20\n",
      "6s - loss: 2.3734 - acc: 0.8328 - val_loss: 2.9967 - val_acc: 0.7926\n",
      "Epoch 11/20\n",
      "6s - loss: 2.3695 - acc: 0.8337 - val_loss: 2.7432 - val_acc: 0.8088\n",
      "Epoch 12/20\n",
      "6s - loss: 2.3314 - acc: 0.8370 - val_loss: 2.5879 - val_acc: 0.8196\n",
      "Epoch 13/20\n",
      "6s - loss: 2.2898 - acc: 0.8401 - val_loss: 2.8536 - val_acc: 0.8050\n",
      "Epoch 14/20\n",
      "6s - loss: 2.2146 - acc: 0.8443 - val_loss: 2.8954 - val_acc: 0.7987\n",
      "Epoch 15/20\n",
      "6s - loss: 2.2268 - acc: 0.8441 - val_loss: 2.6577 - val_acc: 0.8146\n",
      "Epoch 16/20\n",
      "6s - loss: 2.1914 - acc: 0.8464 - val_loss: 2.6294 - val_acc: 0.8179\n",
      "Epoch 17/20\n",
      "6s - loss: 2.1884 - acc: 0.8475 - val_loss: 2.6855 - val_acc: 0.8137\n",
      "Epoch 18/20\n",
      "6s - loss: 2.1457 - acc: 0.8500 - val_loss: 2.4966 - val_acc: 0.8269\n",
      "Epoch 19/20\n",
      "6s - loss: 2.1129 - acc: 0.8520 - val_loss: 2.6979 - val_acc: 0.8120\n",
      "Epoch 20/20\n",
      "6s - loss: 2.1622 - acc: 0.8501 - val_loss: 2.4529 - val_acc: 0.8304\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbec5304f98>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training\n",
    "model.fit(X_train_inception_features, y_train, epochs=20, batch_size=128, validation_split=0.2, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bottle neck feature for tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_x_test = np.array([scipy.misc.imresize(img, (139, 139, 3)) \n",
    "                            for img in x_test]).astype('float32')\n",
    "inception_input_test = preprocess_input(big_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_inception_features = inception_model.predict(inception_input_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9760/10000 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.82450000000000001"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test_inception_features, y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
